{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    exp = \"003\"\n",
    "    ver = \"001\"\n",
    "    training = True\n",
    "    resume = False\n",
    "\n",
    "    project_name = f'pii-{exp}-{ver}'\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    num_proc = 4\n",
    "    val_size = 1000\n",
    "\n",
    "    threshold = 0.99\n",
    "\n",
    "    tokenize_options = {\n",
    "        \"return_offsets_mapping\": True,\n",
    "        \"truncation\": True,\n",
    "        \"max_length\": 3072,\n",
    "    }\n",
    "    deberta_options = {\n",
    "        \"output_hidden_states\": True,\n",
    "        \"hidden_dropout_prob\": 0.1,\n",
    "        \"layer_norm_eps\": 1e-7,\n",
    "        \"add_pooling_layer\": False,\n",
    "    }\n",
    "\n",
    "    model_name = \"deberta3base-truncation-false\"\n",
    "    freeze_emb = False\n",
    "    num_freeze_layers = 3\n",
    "\n",
    "    save_dir = f\"/kaggle/input/{project_name}\"\n",
    "    save_path = f\"{save_dir}/{model_name}.ckpt\"\n",
    "\n",
    "    output_dir = \"/kaggle/output\"\n",
    "\n",
    "    model_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\"\n",
    "\n",
    "    train_path = \"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"\n",
    "    test_path = \"/kaggle/input/pii-detection-removal-from-educational-data/test.json\"\n",
    "    moredata_path = \"/kaggle/input/fix-punctuation-tokenization-external-dataset/moredata_dataset_fixed.json\"\n",
    "    pii_dataset_fixed_path = \"/kaggle/input/fix-punctuation-tokenization-external-dataset/pii_dataset_fixed.json\"\n",
    "    mpware_path = \"/kaggle/input/pii-mixtral8x7b-generated-essays/mpware_mixtral8x7b_v1.1-no-i-username.json\"\n",
    "    sample_sub_path = '/kaggle/input/pii-detection-removal-from-educational-data/sample_submission.csv'\n",
    "\n",
    "    batch_size = 1\n",
    "    epochs = 3\n",
    "    lr = 1e-5\n",
    "\n",
    "    all_labels = [\n",
    "        \"B-EMAIL\",\n",
    "        \"B-ID_NUM\",\n",
    "        \"B-NAME_STUDENT\",\n",
    "        \"B-PHONE_NUM\",\n",
    "        \"B-STREET_ADDRESS\",\n",
    "        \"B-URL_PERSONAL\",\n",
    "        \"B-USERNAME\",\n",
    "        \"I-ID_NUM\",\n",
    "        \"I-NAME_STUDENT\",\n",
    "        \"I-PHONE_NUM\",\n",
    "        \"I-STREET_ADDRESS\",\n",
    "        \"I-URL_PERSONAL\",\n",
    "        \"O\",\n",
    "    ]\n",
    "    num_pii_labels = len(all_labels) - 1\n",
    "    label2id = {label: index for index, label in enumerate(all_labels)}\n",
    "    id2label = {index: label for index, label in enumerate(all_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "sys.path.append('/kaggle/input/piimetric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.5)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.30.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, argparse, torch, sys, random, gc, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functools\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import ctypes\n",
    "from tqdm import tqdm\n",
    "# from rich import print\n",
    "\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, ModelSummary\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from comp_metric import compute_metrics\n",
    "\n",
    "# Transformer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    PreTrainedTokenizer,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    DebertaV2Config,\n",
    "    DebertaV2Model,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    EvalPrediction,\n",
    ")\n",
    "from transformers.modeling_outputs import BaseModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Seed the same seed to all \n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_everything(Config.seed)\n",
    "\n",
    "\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "def clear_memory():\n",
    "    libc.malloc_trim(0)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre Processeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_sampling(df: pd.DataFrame, n_samples: int):\n",
    "    # Get the sample df\n",
    "    samples_df = df.sample(n=n_samples, random_state=Config.seed)\n",
    "    # The remaining df\n",
    "    cond = df[\"document\"].isin(samples_df[\"document\"])\n",
    "    others_df = df.drop(df[cond].index, inplace=False)\n",
    "    return samples_df, others_df\n",
    "\n",
    "\n",
    "def load_train_data():\n",
    "    df_original = pd.read_json(Path(Config.train_path))\n",
    "    print(f\"kaggle train data = {len(df_original)}\")\n",
    "\n",
    "    df_extra = pd.read_json(Path(Config.mpware_path))\n",
    "    print(f\"mpware data = {len(df_extra)}\")\n",
    "\n",
    "        # df_more = pd.read_json(Path(Config.moredata_path))\n",
    "    # df_fix = pd.read_json(Path(Config.pii_dataset_fixed_path))\n",
    "    # df_extra = pd.concat([df_more, df_fix])\n",
    "    # print(f\"moredata + pii_dataset_fixed = {len(df_extra)}\")\n",
    "\n",
    "\n",
    "    df_original[\"is_original\"] = True\n",
    "    df_extra[\"is_original\"] = False\n",
    "\n",
    "    df = pd.concat([df_original, df_extra])\n",
    "    df[\"document\"] = [i for i in range(len(df))]  # Update the document id\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df[\"is_labels\"] = df[\"labels\"].apply(\n",
    "        lambda labels: any(label != \"O\" for label in labels)\n",
    "    )\n",
    "\n",
    "    df_original = df[df[\"is_original\"]]\n",
    "    df_extra = df[~df[\"is_original\"]]\n",
    "\n",
    "    # One or more labels are not 'O'\n",
    "    true_labels = df_original[df_original[\"is_labels\"]]\n",
    "    # all labels are 'O'\n",
    "    false_labels = df_original[~df_original[\"is_labels\"]]\n",
    "\n",
    "    # Reset index to two df\n",
    "    true_labels = true_labels.reset_index(drop=True, inplace=False)\n",
    "    false_labels = false_labels.reset_index(drop=True, inplace=False)\n",
    "    print(f\"Number of true_labels = {len(true_labels)}\")\n",
    "    print(f\"Number of false_labels = {len(false_labels)}\")\n",
    "\n",
    "    # Get 300 as valid dataset\n",
    "    n_true_samples = len(true_labels) - int(Config.val_size * len(true_labels) / len(df_original))\n",
    "\n",
    "    # Sample true labels\n",
    "    true_samples, true_others = split_df_by_sampling(true_labels, n_true_samples)\n",
    "    print(f\"true_samples = {len(true_samples)} true_others = {len(true_others)}\")\n",
    "    n_samples = len(false_labels) - (Config.val_size - int(Config.val_size * len(true_labels) / len(df_original)))\n",
    "    # Sample false labels\n",
    "    false_samples, false_others = split_df_by_sampling(false_labels, n_samples)\n",
    "    print(f\"false_samples = {len(false_samples)} false_others = {len(false_others)}\")\n",
    "    # Training ds = P * true_labels + P * false_labels\n",
    "    train_df = pd.concat([true_samples, false_samples, df_extra])\n",
    "    # Valid ds = (1-P) * true_labels + (1-P) * false_labels\n",
    "    valid_df = pd.concat([true_others, false_others])\n",
    "\n",
    "    return train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer: PreTrainedTokenizer, is_test: bool) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        if is_test:\n",
    "            self.tokenized_df = df.apply(self.tokenize_test, axis=1, result_type=\"expand\")\n",
    "        else:\n",
    "            self.tokenized_df = df.apply(self.tokenize_train, axis=1, result_type=\"expand\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_df)\n",
    "    \n",
    "    def tokenize_train(self, row):\n",
    "        text = []\n",
    "        token_map = []\n",
    "        labels = []\n",
    "        targets = []\n",
    "        idx = 0\n",
    "        for t, l, ws in zip(row[\"tokens\"], row[\"labels\"], row[\"trailing_whitespace\"]):\n",
    "            text.append(t)\n",
    "            labels.extend([l]*len(t))\n",
    "            token_map.extend([idx]*len(t))\n",
    "\n",
    "            if l in Config.all_labels:  \n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0)\n",
    "            \n",
    "            if ws:\n",
    "                text.append(\" \")\n",
    "                labels.append(\"O\")\n",
    "                token_map.append(-1)\n",
    "            idx += 1\n",
    "\n",
    "        tokenized = self.tokenizer(\"\".join(text), **Config.tokenize_options)\n",
    "         \n",
    "        target_num = sum(targets)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        text = \"\".join(text)\n",
    "        token_labels = []\n",
    "\n",
    "        for start_idx, end_idx in tokenized.offset_mapping:\n",
    "            if start_idx == 0 and end_idx == 0: \n",
    "                token_labels.append(Config.label2id[\"O\"])\n",
    "                continue\n",
    "            \n",
    "            if text[start_idx].isspace():\n",
    "                start_idx += 1\n",
    "            try:\n",
    "                token_labels.append(Config.label2id[labels[start_idx]])\n",
    "            except:\n",
    "                continue\n",
    "        length = len(tokenized.input_ids)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": tokenized.input_ids,\n",
    "            \"attention_mask\": tokenized.attention_mask,\n",
    "            \"offset_mapping\": tokenized.offset_mapping,\n",
    "            \"labels\": token_labels,\n",
    "            \"length\": length,\n",
    "            \"target_num\": target_num,\n",
    "            \"group\": 1 if target_num > 0 else 0,\n",
    "            \"token_map\": token_map,\n",
    "            \"document\": row[\"document\"],\n",
    "            \"tokens\": row[\"tokens\"],      \n",
    "            \"raw_labels\": row[\"labels\"],     \n",
    "        }\n",
    "\n",
    "    def tokenize_test(self, row):\n",
    "        text = []\n",
    "        token_map = []\n",
    "        \n",
    "        idx = 0\n",
    "        for t, ws in zip(row[\"tokens\"], row[\"trailing_whitespace\"]):\n",
    "            text.append(t)\n",
    "            token_map.extend([idx]*len(t))\n",
    "            if ws:\n",
    "                text.append(\" \")\n",
    "                token_map.append(-1)\n",
    "                \n",
    "            idx += 1\n",
    "            \n",
    "        tokenized = self.tokenizer(\"\".join(text), **Config.tokenize_options)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": tokenized.input_ids,\n",
    "            \"attention_mask\": tokenized.attention_mask,\n",
    "            \"offset_mapping\": tokenized.offset_mapping,\n",
    "            \"token_map\": token_map,       \n",
    "            \"document\": row[\"document\"],\n",
    "            \"tokens\": row[\"tokens\"],         \n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            row = self.tokenized_df.drop([\"document\", \"tokens\"], axis=1).iloc[index]\n",
    "        else:\n",
    "            row = self.tokenized_df.drop([\"document\", \"tokens\", \"raw_labels\"], axis=1).iloc[index]\n",
    "        return row\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    DataFrameからモデリング時に使用するDataModuleを作成\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        valid_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.test_df = test_df\n",
    "        self.batch_size = Config.batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.collator = DataCollatorForTokenClassification(\n",
    "            tokenizer, pad_to_multiple_of=512\n",
    "        )\n",
    "        self.reference_df = self.create_val_reference_df(valid_df)\n",
    "\n",
    "    def create_val_reference_df(self, valid_df: pd.DataFrame):\n",
    "        valid_df = valid_df[['document', 'tokens', 'labels']].copy()\n",
    "        valid_df = valid_df.explode(['tokens', 'labels']).reset_index(drop=True).rename(columns={'tokens': 'token', 'labels': 'label'})\n",
    "        valid_df['token'] = valid_df.groupby('document').cumcount()\n",
    "        \n",
    "        reference_df = valid_df[valid_df['label'] != 'O'].copy()\n",
    "        reference_df = reference_df.reset_index().rename(columns={'index': 'row_id'})\n",
    "        reference_df = reference_df[['row_id', 'document', 'token', 'label']].copy()\n",
    "        return reference_df\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = CreateDataset(\n",
    "            self.train_df, self.tokenizer, is_test=False\n",
    "        )\n",
    "        self.valid_dataset = CreateDataset(\n",
    "            self.valid_df, self.tokenizer, is_test=False\n",
    "        )\n",
    "        self.test_dataset = CreateDataset(\n",
    "            self.test_df, self.tokenizer, is_test=True\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            collate_fn=self.collator,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=os.cpu_count(),\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_dataset,\n",
    "            collate_fn=self.collator,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=os.cpu_count(),\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            collate_fn=self.collator,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=os.cpu_count(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dfs():\n",
    "    # Load data\n",
    "    # Split 'df' into training and valid dataset (300) based on whether the row is all 'O' or not. \n",
    "    train_df, valid_df = load_train_data()\n",
    "    train_df.reset_index(drop=True, inplace=True)\n",
    "    valid_df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Number of train_df = {len(train_df)}\")\n",
    "    print(f\"Number of valid_df = {len(valid_df)}\")\n",
    "\n",
    "    test_df = pd.read_json(Path(Config.test_path))\n",
    "    clear_memory()\n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle train data = 6807\n",
      "mpware data = 2692\n",
      "Number of true_labels = 945\n",
      "Number of false_labels = 5862\n",
      "true_samples = 807 true_others = 138\n",
      "false_samples = 5000 false_others = 862\n",
      "Number of train_df = 8499\n",
      "Number of valid_df = 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df, test_df = gen_dfs()\n",
    "tokenizer = AutoTokenizer.from_pretrained(Config.model_path)\n",
    "dm = CreateDataModule(train_df, valid_df, test_df, tokenizer)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing_preds(logits_list: list[torch.Tensor]) -> list[torch.Tensor]:\n",
    "    preds_final = []\n",
    "    for logits in logits_list:\n",
    "        predictions_prob = torch.softmax(logits, dim=-1)\n",
    "        predictions = logits.argmax(-1)\n",
    "        predictions_without_O = predictions_prob[:, :12].argmax(-1)\n",
    "\n",
    "        O_prob = predictions_prob[:, 12]\n",
    "        pred_final = torch.where(\n",
    "            O_prob < Config.threshold, predictions_without_O, predictions\n",
    "        )\n",
    "        preds_final.append(pred_final)\n",
    "\n",
    "    return preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_df(preds_list: list[torch.Tensor], tokenized_df: pd.DataFrame):\n",
    "    triplets = []\n",
    "    pairs = set()\n",
    "    document, token, label, token_str = [], [], [], []\n",
    "    for preds, token_map, offsets, tokens, doc in zip(\n",
    "        preds_list,\n",
    "        tokenized_df[\"token_map\"],\n",
    "        tokenized_df[\"offset_mapping\"],\n",
    "        tokenized_df[\"tokens\"],\n",
    "        tokenized_df[\"document\"],\n",
    "    ):\n",
    "        # p = p.argmax(-1).cpu().detach().numpy()\n",
    "        preds = preds.cpu().detach().numpy()\n",
    "\n",
    "        for token_pred, (start_idx, end_idx) in zip(preds, offsets):\n",
    "            label_pred = Config.id2label[(token_pred)]\n",
    "\n",
    "            if start_idx + end_idx == 0:\n",
    "                continue\n",
    "\n",
    "            if token_map[start_idx] == -1:\n",
    "                start_idx += 1\n",
    "\n",
    "            # ignore \"\\n\\n\"\n",
    "            while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "                start_idx += 1\n",
    "\n",
    "            if start_idx >= len(token_map):\n",
    "                break\n",
    "\n",
    "            token_id = token_map[start_idx]\n",
    "\n",
    "            if label_pred == \"O\" or token_id == -1:\n",
    "                continue\n",
    "\n",
    "            pair = (doc, token_id)\n",
    "\n",
    "            if pair in pairs:\n",
    "                continue\n",
    "\n",
    "            document.append(doc)\n",
    "            token.append(token_id)\n",
    "            label.append(label_pred)\n",
    "            token_str.append(tokens[token_id])\n",
    "            pairs.add(pair)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\"document\": document, \"token\": token, \"label\": label, \"token_str\": token_str}\n",
    "    )\n",
    "    df[\"row_id\"] = list(range(len(df)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(module: nn.Module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "class LSTMHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            in_features,\n",
    "            hidden_dim,\n",
    "            n_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.1,\n",
    "        )\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        self.lstm.flatten_parameters()\n",
    "        hidden, (_, _) = self.lstm.forward(x)\n",
    "        out = hidden\n",
    "        return out\n",
    "\n",
    "\n",
    "class DebertaLSTMModel(pl.LightningModule):\n",
    "    def __init__(self, dm: CreateDataModule):\n",
    "        super(DebertaLSTMModel, self).__init__()\n",
    "\n",
    "        # self.example_input_array = torch.Tensor(1, 1).to(dtype=torch.int64)\n",
    "        self.dm = dm\n",
    "\n",
    "        self.model_config: DebertaV2Config = AutoConfig.from_pretrained(\n",
    "            Config.model_path\n",
    "        )\n",
    "\n",
    "        self.model_config.update(Config.deberta_options)\n",
    "\n",
    "        self.transformers_model: DebertaV2Model = AutoModel.from_pretrained(\n",
    "            Config.model_path, config=self.model_config\n",
    "        )\n",
    "        self.transformers_model.gradient_checkpointing_enable()\n",
    "        self.num_features = self.transformers_model.config.hidden_size * 3\n",
    "\n",
    "        self.head = LSTMHead(\n",
    "            in_features=self.num_features,\n",
    "            hidden_dim=self.num_features // 2,\n",
    "            n_layers=1,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.num_features, len(Config.all_labels))\n",
    "        self.loss_function = nn.CrossEntropyLoss(reduction='mean',ignore_index=-100) \n",
    "        self.validation_step_outputs = []        \n",
    "\n",
    "        if Config.freeze_emb:\n",
    "            freeze(self.transformers_model.embeddings)\n",
    "        if Config.num_freeze_layers:\n",
    "            freeze(self.transformers_model.encoder.layer[:Config.num_freeze_layers])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, train=True):\n",
    "        transformer_out: BaseModelOutput = self.transformers_model.forward(\n",
    "            input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        hidden_states = transformer_out.hidden_states\n",
    "        transformer_features = torch.cat(hidden_states[-3:], dim=-1)\n",
    "        assert transformer_features.shape[-1] == self.num_features\n",
    "        head_output = self.head.forward(transformer_features)\n",
    "        # last_hidden_state = (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        logits = self.fc.forward(head_output)\n",
    "\n",
    "        # logits = (batch_size, seq_len, num_labels)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        target: torch.Tensor = batch[\"labels\"]\n",
    "\n",
    "        logits = self.forward(input_ids, attention_mask, train=True)\n",
    "        # output = (seq_len, num_labels)\n",
    "        loss = self.loss_function(\n",
    "            logits.view(-1, len(Config.all_labels)), target.view(-1)\n",
    "        )\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def train_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        print(f\"epoch {self.trainer.current_epoch} training loss {avg_loss}\")\n",
    "        return {\"train_loss\": avg_loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids: torch.Tensor = batch[\"input_ids\"]\n",
    "        attention_mask: torch.Tensor = batch[\"attention_mask\"]\n",
    "        target: torch.Tensor = batch[\"labels\"]\n",
    "\n",
    "        logits = self.forward(input_ids, attention_mask, train=False)\n",
    "        # logits.shape = (batch_size, seq_len, num_labels)\n",
    "\n",
    "        loss = self.loss_function(\n",
    "            logits.view(-1, len(Config.all_labels)), target.view(-1)\n",
    "        )\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.validation_step_outputs.append(\n",
    "            {\"val_loss\": loss, \"logits\": logits, \"targets\": target}\n",
    "        )\n",
    "        return {\"val_loss\": loss, \"logits\": logits, \"targets\": target}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        outputs = self.validation_step_outputs\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        logits_list = [logits for batch in outputs for logits in batch[\"logits\"]]\n",
    "        preds_list = post_processing_preds(logits_list)\n",
    "        \n",
    "        pred_df = predictions_to_df(preds_list, self.dm.valid_dataset.tokenized_df)\n",
    "\n",
    "        self.validation_step_outputs = []    \n",
    "\n",
    "        avg_score = compute_metrics(pred_df, self.dm.reference_df)\n",
    "        f5_score = avg_score[\"ents_f5\"]\n",
    "        self.log(\"precision\", avg_score[\"ents_p\"])\n",
    "        self.log(\"recall\", avg_score[\"ents_r\"])\n",
    "        self.log(\"f5\", avg_score[\"ents_f5\"])\n",
    "        \n",
    "        print(f\"epoch {self.trainer.current_epoch} validation loss {avg_loss}\")\n",
    "        print(avg_score[\"ents_per_type\"])\n",
    "\n",
    "        return {\"val_loss\": avg_loss, \"val_f5\": f5_score}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        input_ids: torch.Tensor = batch[\"input_ids\"]\n",
    "        attention_mask: torch.Tensor = batch[\"attention_mask\"]\n",
    "\n",
    "        logits = self.forward(input_ids, attention_mask, train=False)\n",
    "        return logits\n",
    "\n",
    "    def get_optimizer_params(self, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.transformers_model.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"lr\": encoder_lr,\n",
    "                \"weight_decay\": weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.transformers_model.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"lr\": encoder_lr,\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.named_parameters()\n",
    "                    if \"transformers_model\" not in n\n",
    "                ],\n",
    "                \"lr\": decoder_lr,\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=Config.lr)\n",
    "\n",
    "        epoch_steps = len(self.dm.train_dataset)\n",
    "        batch_size = Config.batch_size\n",
    "\n",
    "        warmup_steps = 0.05 * epoch_steps // batch_size\n",
    "        training_steps = Config.epochs * epoch_steps // batch_size\n",
    "        # scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,training_steps,-1)\n",
    "        # scheduler = get_polynomial_decay_schedule_with_warmup(optimizer, warmup_steps, training_steps, lr_end=1e-6, power=3.0)\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, warmup_steps, training_steps, num_cycles=0.5\n",
    "        )\n",
    "\n",
    "        lr_scheduler_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"step\",\n",
    "            \"frequency\": 1,\n",
    "        }\n",
    "\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/scripts/exp003/wandb/run-20240330_074526-it7laz0z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hzume/pii-003-001/runs/it7laz0z/workspace' target=\"_blank\">stilted-river-8</a></strong> to <a href='https://wandb.ai/hzume/pii-003-001' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hzume/pii-003-001' target=\"_blank\">https://wandb.ai/hzume/pii-003-001</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hzume/pii-003-001/runs/it7laz0z/workspace' target=\"_blank\">https://wandb.ai/hzume/pii-003-001/runs/it7laz0z/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:398: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /kaggle/input/pii-003-001 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d90e6f5b59b48bbad2eaee2e4e9afdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation loss 2.564984083175659\n",
      "{'URL_PERSONAL': {'p': 0.0, 'r': 0.0, 'f5': 0.0}, 'EMAIL': {'p': 0.0, 'r': 0.0, 'f5': 0.0}, 'USERNAME': {'p': 0.0, 'r': 0.0, 'f5': 0.0}, 'STREET_ADDRESS': {'p': 0.0, 'r': 0.0, 'f5': 0.0}, 'NAME_STUDENT': {'p': 0.0, 'r': 0.0, 'f5': 0.0}, 'ID_NUM': {'p': 0.0, 'r': 0.0, 'f5': 0.0}, 'PHONE_NUM': {'p': 0.0, 'r': 0.0, 'f5': 0.0}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531b9dbd13a443bd9c580b001da1d17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78606297e77343ce927126935fa7097b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation loss 0.012347443960607052\n",
      "{'NAME_STUDENT': {'p': 0.006292749658002736, 'r': 0.06036745406824147, 'f5': 0.045371775417298935}, 'URL_PERSONAL': {'p': 0.0027063599458728013, 'r': 1.0, 'f5': 0.0659062103929024}, 'STREET_ADDRESS': {'p': 0.0, 'r': 0.0, 'f5': 0.0}, 'EMAIL': {'p': 0.0, 'r': 0.0, 'f5': 0.0}, 'ID_NUM': {'p': 0.0, 'r': 0.0, 'f5': 0.0}, 'PHONE_NUM': {'p': 0.0, 'r': 0.0, 'f5': 0.0}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686e898ff2814b5897ad1df3b66a2dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation loss 0.006115811411291361\n",
      "{'NAME_STUDENT': {'p': 0.14380081300813008, 'r': 0.7427821522309711, 'f5': 0.6402157835204038}, 'URL_PERSONAL': {'p': 0.03934426229508197, 'r': 1.0, 'f5': 0.5157024793388431}, 'STREET_ADDRESS': {'p': 0.5625, 'r': 0.8181818181818182, 'f5': 0.8041237113402062}, 'EMAIL': {'p': 0.4166666666666667, 'r': 0.625, 'f5': 0.6132075471698113}, 'ID_NUM': {'p': 1.0, 'r': 0.5, 'f5': 0.5098039215686274}, 'PHONE_NUM': {'p': 0.0, 'r': 0.0, 'f5': 0.0}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a35d51cf1e643ef876b1882568b92c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation loss 0.0035959044471383095\n",
      "{'NAME_STUDENT': {'p': 0.5063694267515924, 'r': 0.8346456692913385, 'f5': 0.8143405889884763}, 'STREET_ADDRESS': {'p': 0.6923076923076923, 'r': 0.8181818181818182, 'f5': 0.8125000000000002}, 'ID_NUM': {'p': 0.6, 'r': 0.75, 'f5': 0.7428571428571428}, 'URL_PERSONAL': {'p': 0.6111111111111112, 'r': 0.9166666666666666, 'f5': 0.8993710691823898}, 'EMAIL': {'p': 0.75, 'r': 0.75, 'f5': 0.75}, 'PHONE_NUM': {'p': 0.0, 'r': 0.0, 'f5': 0.0}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b85896c3854469392d25e2b91a26d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation loss 0.0024881805293262005\n",
      "{'NAME_STUDENT': {'p': 0.37760702524698136, 'r': 0.9028871391076115, 'f5': 0.8570333461096205}, 'URL_PERSONAL': {'p': 0.20689655172413793, 'r': 1.0, 'f5': 0.8715083798882681}, 'STREET_ADDRESS': {'p': 0.6206896551724138, 'r': 0.8181818181818182, 'f5': 0.8082901554404146}, 'EMAIL': {'p': 0.6666666666666666, 'r': 1.0, 'f5': 0.9811320754716982}, 'ID_NUM': {'p': 0.34375, 'r': 0.9166666666666666, 'f5': 0.8614457831325301}, 'PHONE_NUM': {'p': 0.0, 'r': 0.0, 'f5': 0.0}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f083e50253844b0ada9b53a7b9a2eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 validation loss 0.0021531246602535248\n",
      "{'NAME_STUDENT': {'p': 0.693446088794926, 'r': 0.8608923884514436, 'f5': 0.8529705941188237}, 'STREET_ADDRESS': {'p': 0.6428571428571429, 'r': 0.8181818181818182, 'f5': 0.8096885813148791}, 'EMAIL': {'p': 0.5, 'r': 1.0, 'f5': 0.9629629629629629}, 'ID_NUM': {'p': 0.5238095238095238, 'r': 0.9166666666666666, 'f5': 0.8909657320872274}, 'URL_PERSONAL': {'p': 0.3157894736842105, 'r': 1.0, 'f5': 0.9230769230769229}, 'PHONE_NUM': {'p': 1.0, 'r': 1.0, 'f5': 1.0}, 'USERNAME': {'p': 0.0, 'r': 0.0, 'f5': 0.0}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f24014fe1d488da93d8967154f6ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 validation loss 0.0017778610344976187\n",
      "{'NAME_STUDENT': {'p': 0.44746600741656367, 'r': 0.9501312335958005, 'f5': 0.9107799496806658}, 'STREET_ADDRESS': {'p': 0.6206896551724138, 'r': 0.8181818181818182, 'f5': 0.8082901554404146}, 'EMAIL': {'p': 0.7272727272727273, 'r': 1.0, 'f5': 0.985781990521327}, 'ID_NUM': {'p': 0.36666666666666664, 'r': 0.9166666666666666, 'f5': 0.8666666666666668}, 'URL_PERSONAL': {'p': 0.27906976744186046, 'r': 1.0, 'f5': 0.9096209912536443}, 'PHONE_NUM': {'p': 1.0, 'r': 1.0, 'f5': 1.0}, 'USERNAME': {'p': 0.0, 'r': 0.0, 'f5': 0.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d4d65725f641ccba74ebddfb544c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.023 MB of 0.023 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████████</td></tr><tr><td>f5</td><td>▁▆▇███</td></tr><tr><td>precision</td><td>▁▂▇▅█▆</td></tr><tr><td>recall</td><td>▁▆▇█▇█</td></tr><tr><td>train_loss</td><td>█▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>f5</td><td>0.90588</td></tr><tr><td>precision</td><td>0.44541</td></tr><tr><td>recall</td><td>0.94495</td></tr><tr><td>train_loss</td><td>0.00053</td></tr><tr><td>trainer/global_step</td><td>3699</td></tr><tr><td>val_loss</td><td>0.00178</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-river-8</strong> at: <a href='https://wandb.ai/hzume/pii-003-001/runs/it7laz0z/workspace' target=\"_blank\">https://wandb.ai/hzume/pii-003-001/runs/it7laz0z/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240330_074526-it7laz0z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if Config.training:\n",
    "    wandb.login()\n",
    "    id = wandb.util.generate_id()\n",
    "    wandb.init(project=Config.project_name, id=id, resume=\"allow\")\n",
    "    # if Config.resume:\n",
    "    #     wandb.init(project=f'pii-{Config.exp}-{Config.ver}', id=\"helpful-water-6\")\n",
    "    wandb_logger = WandbLogger(project=Config.project_name)\n",
    "    model = DebertaLSTMModel(dm=dm)\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\", min_delta=0.00, patience=8, verbose=True, mode=\"min\"\n",
    "    )\n",
    "    Path(Config.save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(Config.save_dir).joinpath(\"dataset-metadata.json\"), \"w\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"title\": Config.project_name,\n",
    "                \"id\": f\"zume666/{Config.project_name}\",\n",
    "                \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
    "            },\n",
    "            f,\n",
    "        )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        dirpath=Config.save_dir,\n",
    "        save_top_k=1,\n",
    "        save_last=True,\n",
    "        save_weights_only=False,\n",
    "        filename=Config.model_name,\n",
    "        verbose=True,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=Config.epochs,\n",
    "        deterministic=True,\n",
    "        val_check_interval=0.25,\n",
    "        accumulate_grad_batches=4,\n",
    "        devices=[0],\n",
    "        precision=\"bf16-mixed\",\n",
    "        accelerator=\"gpu\",\n",
    "        callbacks=[\n",
    "            checkpoint_callback,\n",
    "            early_stop_callback,\n",
    "            ModelSummary(max_depth=-1),\n",
    "        ],\n",
    "        logger=wandb_logger,\n",
    "    )\n",
    "    if Config.resume:\n",
    "        trainer.fit(\n",
    "            model=model,\n",
    "            datamodule=dm,\n",
    "            ckpt_path=Path(Config.save_dir).joinpath(\"last.ckpt\"),\n",
    "        )\n",
    "    else:\n",
    "        trainer.fit(model=model, datamodule=dm)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dm: CreateDataModule, model: pl.LightningModule):\n",
    "    model.eval()  \n",
    "    model.to(DEVICE)\n",
    "    test_dataloader = dm.test_dataloader()\n",
    "    \n",
    "    trainer = pl.Trainer()\n",
    "    outputs = trainer.predict(model=model, dataloaders=test_dataloader, ckpt_path=Config.save_path)\n",
    "        \n",
    "    logits_list = [logits for batch in outputs for logits in batch]\n",
    "    preds_list = post_processing_preds(logits_list)\n",
    "\n",
    "    pred_df = predictions_to_df(preds_list, dm.test_dataset.tokenized_df)\n",
    "\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m~\u001b[39mConfig\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m DebertaLSTMModel(dm\u001b[38;5;241m=\u001b[39mdm)\n\u001b[0;32m----> 3\u001b[0m     sub_df \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     sample_sub \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(Config\u001b[38;5;241m.\u001b[39msample_sub_path)\n\u001b[1;32m      5\u001b[0m     sub_df \u001b[38;5;241m=\u001b[39m sub_df[sample_sub\u001b[38;5;241m.\u001b[39mcolumns]\n",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(dm, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39mtest_dataloader()\n\u001b[1;32m      6\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer()\n\u001b[0;32m----> 7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m logits_list \u001b[38;5;241m=\u001b[39m [logits \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m outputs \u001b[38;5;28;01mfor\u001b[39;00m logits \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     10\u001b[0m preds_list \u001b[38;5;241m=\u001b[39m post_processing_preds(logits_list)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:852\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    851\u001b[0m _verify_strategy_supports_compile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:894\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(model, predict_dataloaders\u001b[38;5;241m=\u001b[39mdataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule)\n\u001b[1;32m    891\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    893\u001b[0m )\n\u001b[0;32m--> 894\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:946\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mrestore_checkpoint_after_setup:\n\u001b[1;32m    945\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: restoring module and callbacks from checkpoint path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 946\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_restore_modules_and_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: configuring sharded model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    949\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_configure_sharded_model(\u001b[38;5;28mself\u001b[39m)  \u001b[38;5;66;03m# allow user to setup in model sharded environment\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:400\u001b[0m, in \u001b[0;36m_CheckpointConnector._restore_modules_and_callbacks\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_restore_modules_and_callbacks\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint_path: Optional[_PATH] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;66;03m# restore modules after setup\u001b[39;00m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_start(checkpoint_path)\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_datamodule()\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# restore callback states\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:280\u001b[0m, in \u001b[0;36m_CheckpointConnector.restore_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_load_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded_checkpoint)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# restore model state_dict\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loaded_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:364\u001b[0m, in \u001b[0;36mStrategy.load_model_state_dict\u001b[0;34m(self, checkpoint)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint: Mapping[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DebertaLSTMModel:\n\tsize mismatch for head.lstm.weight_ih_l0: copying a param with shape torch.Size([2304, 1152]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for head.lstm.weight_hh_l0: copying a param with shape torch.Size([2304, 576]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for head.lstm.bias_ih_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for head.lstm.bias_hh_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for head.lstm.weight_ih_l0_reverse: copying a param with shape torch.Size([2304, 1152]) from checkpoint, the shape in current model is torch.Size([768, 384]).\n\tsize mismatch for head.lstm.weight_hh_l0_reverse: copying a param with shape torch.Size([2304, 576]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for head.lstm.bias_ih_l0_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for head.lstm.bias_hh_l0_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([13, 1152]) from checkpoint, the shape in current model is torch.Size([13, 384])."
     ]
    }
   ],
   "source": [
    "if ~Config.training:\n",
    "    model = DebertaLSTMModel(dm=dm)\n",
    "    sub_df = predict(dm, model)\n",
    "    sample_sub = pd.read_csv(Config.sample_sub_path)\n",
    "    sub_df = sub_df[sample_sub.columns]\n",
    "    sub_df.to_csv('submission.csv',index=False)\n",
    "    display(sub_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert preds to a list of dictionaries\n",
    "# results = []\n",
    "# for preds, token_map, offsets, tokens, doc in zip(preds_final,\n",
    "#                                               tokenized_ds[\"token_map\"], \n",
    "#                                               tokenized_ds[\"offset_mapping\"],\n",
    "#                                               tokenized_ds[\"tokens\"],\n",
    "#                                               tokenized_ds[\"document\"]):\n",
    "#     for token_pred, (start_idx, end_idx) in zip(preds, offsets):\n",
    "#         try:\n",
    "#             label_pred = Config.id2label[str(token_pred)]\n",
    "#             if start_idx + end_idx == 0: \n",
    "#                 continue\n",
    "\n",
    "#             if token_map[start_idx] == -1:\n",
    "#                 start_idx += 1\n",
    "#              # ignore \"\\n\\n\"\n",
    "#             while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "#                 start_idx += 1\n",
    "\n",
    "#             if start_idx >= len(token_map): \n",
    "#                 break\n",
    "\n",
    "#             token_id = token_map[start_idx]\n",
    "\n",
    "#             # ignore \"O\" predictions and whitespace preds\n",
    "#             if label_pred != \"O\" and token_id != -1:\n",
    "#                 results.append({\n",
    "#                         \"document\": doc,\n",
    "#                         \"token\": token_id,\n",
    "#                         \"label\": label_pred,\n",
    "#                         \"token_str\": tokens[token_id]\n",
    "#                     })\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error {e}\")\n",
    "#             print(f\"token_map {len(token_map)} and {token_pred}  {start_idx} {end_idx}\")\n",
    "#             sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from spacy.lang.en import English\n",
    "# nlp = English()\n",
    "\n",
    "# def find_span(target: list[str], document: list[str]) -> list[list[int]]:\n",
    "#     idx = 0\n",
    "#     spans = []\n",
    "#     span = []\n",
    "    \n",
    "#     for i, token in enumerate(document):\n",
    "#         if token != target[idx]:\n",
    "#             idx = 0\n",
    "#             span = []\n",
    "#             continue\n",
    "#         span.append(i)\n",
    "        \n",
    "#         idx += 1\n",
    "#         if idx == len(target):\n",
    "#             spans.append(span)\n",
    "#             span = []\n",
    "#             idx = 0\n",
    "#             continue\n",
    "    \n",
    "#     return spans\n",
    "\n",
    "# email_regex = re.compile(r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\n",
    "# phone_num_regex = re.compile(r\"(\\(\\d{3}\\)\\d{3}\\-\\d{4}\\w*|\\d{3}\\.\\d{3}\\.\\d{4})\\s\")\n",
    "# emails = []\n",
    "# phone_nums = []\n",
    "\n",
    "# for _data in test_ds:\n",
    "#     # email\n",
    "#     for token_idx, token in enumerate(_data[\"tokens\"]):\n",
    "#         if re.fullmatch(email_regex, token) is not None:\n",
    "#             emails.append(\n",
    "#                 {\"document\": _data[\"document\"], \"token\": token_idx, \"label\": \"B-EMAIL\", \"token_str\": token}\n",
    "#             )\n",
    "#     # phone number\n",
    "#     matches = phone_num_regex.findall(_data[\"full_text\"])\n",
    "#     if not matches:\n",
    "#         continue\n",
    "        \n",
    "#     for match in matches:\n",
    "#         target = [t.text for t in nlp.tokenizer(match)]\n",
    "#         matched_spans = find_span(target, _data[\"tokens\"])\n",
    "        \n",
    "#     for matched_span in matched_spans:\n",
    "#         for intermediate, token_idx in enumerate(matched_span):\n",
    "#             prefix = \"I\" if intermediate else \"B\"\n",
    "#             phone_nums.append(\n",
    "#                 {\"document\": _data[\"document\"], \"token\": token_idx, \"label\": f\"{prefix}-PHONE_NUM\", \"token_str\": _data[\"tokens\"][token_idx]}\n",
    "#             )\n",
    "\n",
    "# results.extend(emails)\n",
    "# results.extend(phone_nums)\n",
    "\n",
    "# def remove_duplicates(df: pd.DataFrame):\n",
    "#     # Sort by the document and token\n",
    "#     df.sort_values(by=['document', 'token'])\n",
    "#     # Combine three columns \n",
    "#     df['triplet'] = df[[\"document\", \"token\", \"label\"]].apply(lambda row: '_'.join(row.values.astype(str)), axis=1) \n",
    "#     # display(df)\n",
    "#     # Drop duplicated triplets and keep the first one as unique row\n",
    "#     df = df.drop_duplicates(subset=[\"triplet\"], keep='first')\n",
    "#     # Regenerate 'row_id'\n",
    "#     df['row_id'] = list(range(len(df)))    \n",
    "#     df = df.reset_index(drop=True, inplace=False) \n",
    "#     print(\"Remove duplicates\")\n",
    "# #     display(df)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.DataFrame(results)\n",
    "# test_df = remove_duplicates(test_df)\n",
    "# test_df = test_df[[\"row_id\", \"document\", \"token\", \"label\"]]\n",
    "# # Create submission df\n",
    "# test_df.to_csv(\"submission.csv\", index=False)\n",
    "# display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
